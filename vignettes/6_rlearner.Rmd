---
title: "R Learner"
author: "Niklas Rindtorff"
date: "4/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rlearner)
library(randomizr)
library(here)
```

```{r}
allocation <- read_csv(here("data/allocation.csv")) %>% mutate(cosmic_id = as.character(cosmic_id))
covariates <- read_csv(here("data/covariates.csv")) %>% mutate(cosmic_id = as.character(cosmic_id))

load(here("data/crxg_map_imputed.Rdata"))
load(here("data/mutation.Rdata"))
load(here("data/expression.Rdata"))

```

I source a set of functions, I will aggregate all of this in a package later. 

```{r, message=FALSE}
list.files(here("R"), full.names = TRUE) %>% lapply(source)
```


Similar to many causal inference problems, we have three datasets: unit covariates *X*, assignment *w* and responses *y*. 

First, I create a harmonized group of datasets. 

```{r}
# I define my covariate data
X <- mutation %>% mutate(cosmic_id = as.character(cosmic_id)) %>% 
 #inner_join(expression %>% mutate(cosmic_id = as.character(cosmic_id))) %>% 
 # inner_join(cnv %>% mutate(cosmic_id = as.character(cosmic_id))) %>% 
  inner_join(covariates %>% mutate(cosmic_id = as.character(cosmic_id)))


# I filter the dataset so the data is complete for every unit
y_complete <- crxg_map_imputed %>% 
  semi_join(X, by = "cosmic_id") %>% 
  semi_join(allocation, by = "cosmic_id")

X <- X %>% 
  semi_join(crxg_map_imputed, by = "cosmic_id") %>% 
  semi_join(allocation, by = "cosmic_id")

w <- allocation %>% 
  semi_join(X, by = "cosmic_id") %>% 
  semi_join(crxg_map_imputed, by = "cosmic_id")

```


The R-Learner is per default designed to evaluate the CATE of binary treatments. That means, a unit is either treated with a control of an intervention. In our case, we will define a central control arm, Cisplatin, which is commonly used in cases in which no further information about a malignant tumor is available (CUP Syndrome). 

For each treatment, we will train a two-step R-learner and estimate the CATE for the targeted agent vs. Cisplatin. 

Performing this type of star-schema analysis comes with a number of constraints. First, the model will be trained on a smaller number of cases and will likely be less generalizable to CATE estimation problems involving other therapies. Second, this way of analysis does not allow epsilon to be greater than 0, especially if we plan to supply the treatment propensities to the R-Learner.

We define three functions around the R-learner: 
1. A function that estimates the *w* parameter for weighted allocation
1. A function that will take a matrix of assignments based on therapeutic protocols and will introduce random re-assignments based on the parameters epsilon and gamma. 
1. A function that will take the assignment matrix and train R-learners for every treatment arm
1. A function that will collect the predicted CATEs for each treatment arm and calculate an aggregated performance metric

```{r}
estimate_cross(w, epsilon = 0, gamma = 1, omega = 0.1) # %>% knitr::kable()
```

```{r}
re_allocate(w, epsilon = 0, gamma = 0.5, omega = 0.5, ctrl = "cisplatin") %>% 
  mutate(same = assignment == re_assignment)
```


```{r}
draw_interval = 0.05
n_draws = 5

x = rep(seq(0,1, draw_interval), each = n_draws)

allocation_dynamics_gamma <-  x %>% #gamma is scaling automatically
  parallel::mclapply(., re_allocate, allocation = w, ctrl= "cisplatin", epsilon = 0, omega = 0, return_propensity =FALSE) %>% 
  bind_rows() %>% 
  cbind(., gamma = rep(x, each = nrow(w))) %>%
  as_tibble() %>%
  count(gamma, re_assignment) %>% 
  mutate(n = n/n_draws)

allocation_dynamics_gamma %>% 
  ggplot(aes(gamma, n, color = re_assignment)) + 
  geom_point() + 
  geom_line() +
  theme_classic() + 
  scale_color_brewer(type = "qual") + 
   scale_y_log10(limits = c(1, 1000)) +
  labs()
```

```{r}
draw_interval = 0.05
n_draws = 5

x = rep(seq(0,1, draw_interval), each = n_draws)

allocation_dynamics_epsilon <-  x %>% #gamma is scaling automatically
  parallel::mclapply(., re_allocate, allocation = w, ctrl= "cisplatin", gamma = 0, omega = 0,return_propensity =FALSE) %>% 
  bind_rows() %>% 
  cbind(., epsilon = rep(x, each = nrow(w))) %>%
  as_tibble() %>%
  count(epsilon, re_assignment) %>% 
  mutate(n = n/n_draws)

allocation_dynamics_epsilon %>% 
  ggplot(aes(epsilon, n, color = re_assignment)) + 
  geom_point() + 
  geom_line() +
  theme_classic() + 
  scale_color_brewer(type = "qual") + 
   scale_y_log10(limits = c(1, 1000)) +
  labs()
```

```{r}
draw_interval = 0.05
n_draws = 5

x = rep(seq(0,1, draw_interval), each = n_draws)

allocation_dynamics_omega <-  x %>% #gamma is scaling automatically
  parallel::mclapply(., re_allocate, allocation = w, ctrl= "cisplatin", epsilon = 0, gamma = 0,return_propensity =FALSE) %>% 
  bind_rows() %>% 
  cbind(., omega = rep(x, each = nrow(w))) %>%
  as_tibble() %>%
  count(omega, re_assignment) %>% 
  mutate(n = n/n_draws)

allocation_dynamics_omega %>% 
  ggplot(aes(omega, n, color = re_assignment)) + 
  geom_point() + 
  geom_line() +
  theme_classic() + 
  scale_color_brewer(type = "qual") + 
  scale_y_log10(limits = c(1, 1000)) +
  labs()
```


In case of a star-schema analysis, I need to introduce a third parameter, a cross-out rate omega. This parameter describes the rate at which a unit that matched a therapeutic protocol, after applying the cross_over rate,  is allocated into the control arm. Otherwise, these units had a treatment propensity for the control treatment of 0, thereby violating the positivity assumption.

After defining a function to perform weighted reassignments, I have to generate result vectors based on a given reassignment. The function name is *create_y*. 

Now 

```{r}
feed_rlearner <- function(allocation_in, features, response, var, ctrl = "cisplatin"){
  # I create a list to organize elements in the function
list <- list()

list$var = var
list$ctrl = ctrl 

var_q <- sym(var)
ctrl_q <- sym(ctrl)

list$df <- allocation_in$re_allocation %>% 
  mutate(cosmic_id = as.character(cosmic_id)) %>%
  semi_join(response, by = "cosmic_id") %>%
  filter(re_assignment == var |  re_assignment == ctrl) %>% 
  mutate(logical = if_else(re_assignment == ctrl, 0, 1),
         cosmic_id = as.character(cosmic_id))

list$x <- features %>% 
  mutate(cosmic_id = as.character(cosmic_id)) %>%
  semi_join(list$df,  by = "cosmic_id") %>%
  dplyr::select(-cosmic_id) %>%
  mutate_all(funs(as.character)) %>%
  mutate_all(funs(as.numeric)) %>%
  as.matrix()

# getting df into shape

list$df <- list$df %>% 
  semi_join(features %>% 
    mutate(cosmic_id = as.character(cosmic_id)) %>%
    semi_join(list$df,  by = "cosmic_id"), 
  by = "cosmic_id")

list$w <- list$df$logical

list$y <- response %>%
  mutate(cosmic_id = as.character(cosmic_id)) %>%
  left_join(list$df ,.,  by = "cosmic_id") %>%
  dplyr::select_(var, ctrl, "cosmic_id", "re_assignment") %>% 
  mutate(y = if_else(re_assignment == ctrl, !!ctrl_q, !!var_q)) %>% 
  .$y


list$p <- list$df %>% mutate(initial_logical = if_else(re_assignment == ctrl, 0, 1)) %>% 
  mutate(p_hat = if_else(initial_logical == 1, 
                         1-(allocation_in$cross %>% filter(assignment == var) %>% .$cross_out), 
                         allocation_in$cross %>% filter(assignment == var) %>% .$cross_in)) %>% 
  .$p_hat

return(list)
}

train_rlearner <- function(list, estimate_phat = TRUE){
  if(estimate_phat == TRUE){
  # running the rlearner
list$rlasso_fit = rlasso(list$x, list$w, list$y)
list$rlasso_est = predict(list$rlasso_fit, list$x)

list$rboost_fit = rboost(list$x, list$w, list$y)
list$rboost_est = predict(list$rboost_fit, list$x)

return(list)
} else if(estimate_phat == FALSE){
  # running the rlearner
list$rlasso_fit = rlasso(list$x, list$w, list$y, p_hat = list$p)
list$rlasso_est = predict(list$rlasso_fit, list$x)

list$rboost_fit = rboost(list$x, list$w, list$y, p_hat = list$p)
list$rboost_est = predict(list$rboost_fit, list$x)

return(list)
}
}


out <- re_allocate(w, epsilon = 0, gamma = 0.5, omega = 0.5, ctrl = "cisplatin") %>% 
  feed_rlearner(., X, y_complete, var = "trametinib", ctrl = "cisplatin") %>% 
  train_rlearner(., estimate_phat = FALSE)

```


* grid search omega and gamma

Measuring the PEHE for treatment effects.

Different from the initial proposal, I did not modify the PEHE function for a reference-free context. Instead, as described above, I decided to pick a reference treatment, cisplatin.

```{r}
estimate_pehe <- function(rlearner_model, response = y_complete){
  var_q <- sym(rlearner_model$var)
  ctrl_q <- sym(rlearner_model$ctrl)
  
  rlearner_model$df %>% 
    left_join(response, by = "cosmic_id") %>%
    dplyr::select(cosmic_id, !!var_q, !!ctrl_q, assignment, re_assignment, logical) %>%
    mutate(tau = !!var_q-!!ctrl_q) %>% 
    mutate(tau_hat_lasso = rlearner_model$rlasso_est) %>% 
    mutate(tau_hat_boost = rlearner_model$rboost_est) %>% 
    mutate(pehe_lasso = (tau_hat_lasso - tau)^2,
           pehe_boost = (tau_hat_boost - tau)^2) %>% 
    mutate(var = rlearner_model$var,
           ctrl = rlearner_model$ctrl) %>%
    return()
}

estimate_pehe(out) %>% 
  group_by(re_assignment, var) %>% 
  summarise(pehe_lasso_sd = sd(pehe_lasso),
            pehe_boost_sd = sd(pehe_boost),
            pehe_lasso = mean(pehe_lasso),
            pehe_boost = mean(pehe_boost))
```

```{r}
estimate_pehe(out) %>% 
  ggplot(aes(tau_hat_lasso, tau, color = re_assignment)) + 
  geom_point() + 
  theme_classic()
```


# Iterate R-Learner 


```{r}
iterate_rlearner <- function(gamma_omega, var_in){
  params <- gamma_omega %>% str_split(pattern = "_") %>% unlist() %>% as.numeric()
  gamma <- params[1]
  omega <- params[2]
  
  result <- re_allocate(w, epsilon = 0, gamma = gamma, omega = omega, ctrl = "cisplatin") %>% 
  feed_rlearner(., X, y_complete, var = var_in, ctrl = "cisplatin") %>% 
    train_rlearner(., estimate_phat = FALSE) 
  
  result %>%
    saveRDS(here(paste0("data/", gamma_omega, "_", var_in, "_", Sys.time(), ".Rds")))
  
  return(result)
}

rlearner_grid <- expand.grid(gamma = rep(seq(0,1, 0.1), each = 1),
                                omega = rep(seq(0,1, 0.1), each = 1),
                                drug = w[,-1] %>% colnames()) %>% 
  filter(gamma != 0, gamma != 1) %>% 
  filter(omega != 0, omega != 1) %>%
  filter(drug != "cisplatin") %>% 
  mutate(drug = as.character(drug)) %>%
  mutate(gamma_omega = paste0(gamma, "_", omega)) %>%
  mutate(data = map2(gamma_omega,drug, ~ iterate_rlearner(gamma_omega = .x, var_in = .y))) %>% 
  mutate(pehe = map(data, ~ estimate_pehe(.x)))
```

```{r}
rlearner_grid$pehe[[1]] %>% 
  ggplot(aes(tau_hat_lasso, tau, color = re_assignment)) + 
  geom_point() + 
  theme_classic()
```



```{r}
estimate_pehe(out) %>% .$pehe_boost %>% hist()
```

```{r}
out <- re_allocate(w, epsilon = 0.5, ctrl = "cisplatin") %>% 
  train_rlearner(., X, y_complete, var = "trametinib", ctrl = "cisplatin")
```

The performance of the rlearner is far from optimal. I start troubleshooting. 

```{r}
out$rlasso_est %>% hist()
```



```{r}
y_complete %>% 
  ggplot(aes(trametinib, cisplatin)) + 
  geom_point() + 
  theme_classic() + 
  labs(title = "Association of Cisplatin and Trametinib response")
```



```{r}
set.seed(432)
library(rlearner)
n = 100; p = 10

x = matrix(rnorm(n*p), n, p)
w = rbinom(n, 1, 0.5)
#w = cbind(w, c(1, rep(0, times = n-1)))
y = pmax(x[,1], 0) * w + x[,2] + pmin(x[,3], 0) + rnorm(n)

rlasso_fit = rlasso(x, w, y)
rlasso_est = predict(rlasso_fit, x)

rboost_fit = rboost(x, w, y)
rboost_est = predict(rboost_fit, x)
```


```{r}
library(rlearner)
library(zeallot)

# draw a sample of n observations from a simulation
data = toy_data_simulation(n) 
# data$x is a numeric matrix of covariates (each column having a name)
# data$w is a factor vector where the first level indicates "treatment" and the second "control"
# data$y is a numeric vector of outcomes

# Specify the machine learning models and 
# hyperparameters to be cross-validated over.
# This code specifies the use of elastic net
model_specs = list(
	glmnet = list(
	    tune_grid = expand.grid(
	       alpha=c(0,0.5,1),
	       lambda=exp(seq(-5,2,0.2))),
	    extra_args = list())
)

r_fit = rlearner_cv(data$x, data$w, data$y, tau_model_specs=model_specs)
tau_hat = predict(r_fit, data$x)

print(paste("MSE of tau estimate:", mean((data$tau - tau_hat)^2)))
```

